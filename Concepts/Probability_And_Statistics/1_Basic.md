# Probaility(확률)

어떤 일이 일어날 가능성, 비율 혹은 빈도

어떤 사건이 일어날지 완벽하게 예측하기 어렵고, '반드시 발생할 것이다'라고 (대체적으로)단언할 수 없다.

이런 불확실성을 '확률'로 표현한다.

## Random Variable(확률 변수)

"Random" Variable.

시행의 결과에 따라 값이 결정되는 변수를 말한다.

확률 변수는 아직 실제로 관측되진 않았지만, 관측될 수 있는 모든 경우의 수에 해당하는 값을 가질 수 있다.

확률 변수의 종류에는 이산 확률 변수와 연속 확률 변수가 있다.

주사위 눈, 동전 앞뒷면 등은 이산 확률 변수에 속하고

사람의 키, 온도, 특정 시간은 연속 확률 변수에 속한다.

## Expected Value(기댓값)

한 번의 관측으로 얻을 수 있는 값의 평균치.

이산 확률 분포의 기댓값 : $\mathbb E[x] = \sum ^N_{k=1}x_k p(x_k)$

연속 확률 분포의 기댓값 : $\mathbb E[x] = \int^\infty_{-\infty} xp(x)dx$

정의된 식을 바탕으로 해석해보면 기댓값이란, {관측될 수 있는 값}에 {그 값에 대한 확률}을 곱한 {모든 값}을 더한 것이다.

즉 관측될 수 있는 값의 평균치가 기댓값이다.

## Variance(분산)

Random Variable(확률 변수)이 기댓값을 중심으로 얼마나 분포되어 있는지를 나타내는 값.

분산이 클수록 분포가 기대값을 기준으로 퍼지고, 분산이 작을수록 분포가 모여있게 된다.

이산 확률 분포의 분산 : $\mathrm{Var}[x] = \mathbb E[(x-\mu)^2] = \sum^N_{k=1}(x_k-\mu)^2p(x_k)$

연속 확률 분포의 분산 : $\mathrm{Var}[x] = \mathbb E[(x-\mu)^2] = \int^N_{k=1}(x-\mu)^2p(x)dx$

정의된 식을 바탕으로 해석해보면 $x-\mu$는 어떤 값과 평균의 1차원 거리(Distance)를 의미한다.

$(x-\mu)^2p(x)$는 거리의 제곱에 확률을 곱한 값이고, 분산은 이를 모두 더한 값인 것이다.

따라서 분산은 {평균과의 차이}에 대한 {기댓값}, 즉 '평균적인 퍼짐 정도'라고 볼 수 있다.

---
# Normalization constant(정규화 상수)

$f(x)$가 확률 밀도 함수라면 $\int_{-\infty}^{\infty} f(x) , dx = 1$ 을 만족해야 한다.

하지만 $f(x)$가 1로 정규화되지 않은 어떤 함수라면 정규화 상수($Z$)를 도입하여

$f_{normalized}(x) = \frac{f(x)}{Z}$ 와 같이  전체 적분을 1로 만들어주는 것이다.

$Z = \int f(x)dx$

따라서 $\int f_{normalized}(x)dx = \frac{1}{Z} \int f(x)dx = \frac{Z}{Z} = 1$

이 되어 적분값이 1을 만족하는 함수로 변환할 수 있는 것이다.

---
# Likelihood(우도)

관찰된 데이터가 특정 확률 모델(모수)에 의해 생성될 가능성을 나타내는 척도

$L(\theta; x) = P(x|\theta)$

$L(\theta; x)$ : $\theta$라는 파라미터 집합에서 관찰된 데이터($x$)가 나타날 우도

$p(x|\theta)$ : 관찰 데이터 $x$가 주어졌을 때, 모수 $\theta$에 따른 조건부 확률

## 확률과 우도의 차이

$P(x|\theta)$

확률 : $\theta$가 고정, $x$가 변수. 특정 모델 하에서 데이터가 발생할 확률

우도 : $x$가 고정, $\theta$가 변수. 관찰된 데이터 $x$를 기준으로 특정 파라미터 $\theta$가 얼마나 적합한지 나타내는 척도

## Maximum Likelihood Estimation(최대 우도 추정)

$\hat \theta = argmax_\theta L(\theta; x)$

- 관찰된 데이터 $x$를 가장 잘 설명하는 \theta를 찾는 것

## Log-Likelihood(로그 우도)

$l(\theta; x) = \log L(\theta; x)$

- 계산의 편의를 위해 로그우도 사용


## Posterior Probability(사후 확률)

$P(\theta | D)= \frac{P(D|\theta)\cdot P(\theta)}{P(D)}$

- 데이터 $D$가 주어졌을 때 파라미터 집합 $\theta$가 참일 확률

- 우도와 사전확률을 결합하여 추정

- $P(D)는 정규화 상수의 역할을 할 수 있다.

---